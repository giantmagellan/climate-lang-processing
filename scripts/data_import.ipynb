{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = glob.glob(\"data/TelevisionNews/*.csv\")\n",
    "df = []\n",
    "for file in csv_files:\n",
    "    csv = pd.read_csv(file, header=None, names=['URL', 'MatchDateTime', 'Station', 'Show', 'IAShowID','IAPreviewThumb','Snippet'])\n",
    "    csv = csv.iloc[1:] #drow first row containing column names \n",
    "    df.append(csv)\n",
    "df = pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchDateTime</th>\n",
       "      <th>Station</th>\n",
       "      <th>Snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/31/2017 5:53:28</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>beena part to do. the airline industry has not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/18/2017 19:21:01</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>it's beaten it by about 0.1, 0.12 degrees cels...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/5/2017 21:48:46</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>contact more than expected, how. your co nta c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/5/2017 21:13:33</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>where every time a marketplace is closed down,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1/11/2017 3:11:51</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>applause climate change, a controversial issue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1/7/2020 10:27:25</td>\n",
       "      <td>MSNBC</td>\n",
       "      <td>they could be facing. the climate change has m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1/10/2020 1:57:54</td>\n",
       "      <td>MSNBC</td>\n",
       "      <td>fact that they've had a number of decisions th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1/15/2020 5:53:44</td>\n",
       "      <td>MSNBC</td>\n",
       "      <td>i think there were missed opportunities to tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1/5/2020 3:55:58</td>\n",
       "      <td>MSNBC</td>\n",
       "      <td>potentially reshape the democratic primaries. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1/14/2020 5:43:03</td>\n",
       "      <td>MSNBC</td>\n",
       "      <td>beat donald trump, but that is the floor, not ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94858 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          MatchDateTime  Station  \\\n",
       "1     1/31/2017 5:53:28  BBCNEWS   \n",
       "2    1/18/2017 19:21:01  BBCNEWS   \n",
       "3     1/5/2017 21:48:46  BBCNEWS   \n",
       "4     1/5/2017 21:13:33  BBCNEWS   \n",
       "5     1/11/2017 3:11:51  BBCNEWS   \n",
       "..                  ...      ...   \n",
       "198   1/7/2020 10:27:25    MSNBC   \n",
       "199   1/10/2020 1:57:54    MSNBC   \n",
       "200   1/15/2020 5:53:44    MSNBC   \n",
       "201    1/5/2020 3:55:58    MSNBC   \n",
       "202   1/14/2020 5:43:03    MSNBC   \n",
       "\n",
       "                                               Snippet  \n",
       "1    beena part to do. the airline industry has not...  \n",
       "2    it's beaten it by about 0.1, 0.12 degrees cels...  \n",
       "3    contact more than expected, how. your co nta c...  \n",
       "4    where every time a marketplace is closed down,...  \n",
       "5    applause climate change, a controversial issue...  \n",
       "..                                                 ...  \n",
       "198  they could be facing. the climate change has m...  \n",
       "199  fact that they've had a number of decisions th...  \n",
       "200  i think there were missed opportunities to tal...  \n",
       "201  potentially reshape the democratic primaries. ...  \n",
       "202  beat donald trump, but that is the floor, not ...  \n",
       "\n",
       "[94858 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= df.drop(['URL','Show','IAShowID', 'IAPreviewThumb'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MatchDateTime    datetime64[ns]\n",
       "Station          string[python]\n",
       "Snippet          string[python]\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change dtypes \n",
    "df['MatchDateTime'] = pd.to_datetime(df['MatchDateTime'])\n",
    "df['Station'] = df['Station'].astype('string')\n",
    "df['Snippet'] = df['Snippet'].astype('string')\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions\n",
    "\n",
    "punctuation = set(punctuation) # speeds up comparison\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(tokens) :\n",
    "    return [token for token in tokens if token not in sw]\n",
    "    return(tokens)\n",
    "\n",
    "def remove_punctuation(text) :\n",
    "    return \"\".join(ch for ch in text if ch not in punctuation)\n",
    "\n",
    "def tokenize(text) :\n",
    "    tokens = text.split()\n",
    "    return(tokens)\n",
    "\n",
    "def descriptive_stats(tokens, verbose=True) :\n",
    "    num_tokens=len(tokens)\n",
    "    num_unique_tokens = len(set(tokens))\n",
    "    lexical_diversity = num_unique_tokens/num_tokens\n",
    "    num_characters = sum(len(token) for token in tokens)\n",
    "\n",
    "    if verbose :\n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "\n",
    "        # print the five most common tokens\n",
    "        counter = Counter(tokens)\n",
    "        top_5_tokens = counter.most_common(5)\n",
    "        print(\"Top 5 most common tokens:\")\n",
    "        for token, count in top_5_tokens:\n",
    "            print(f\"{token}: {count} occurrences\")\n",
    "\n",
    "    return([num_tokens, num_unique_tokens,\n",
    "            lexical_diversity,\n",
    "            num_characters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of news snippets: 94858\n",
      "News stations: <StringArray>\n",
      "['BBCNEWS', 'CNN', 'FOXNEWS', 'MSNBC']\n",
      "Length: 4, dtype: string\n",
      "\n",
      "Count of snippets for each news station: \n",
      " Station\n",
      "MSNBC      26429\n",
      "FOXNEWS    25865\n",
      "BBCNEWS    23260\n",
      "CNN        19304\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of news snippets:\", len(df))\n",
    "print(\"News stations:\", df['Station'].unique())\n",
    "print(\"\\nCount of snippets for each news station: \\n\",df['Station'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchDateTime</th>\n",
       "      <th>Station</th>\n",
       "      <th>Snippet</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-31 05:53:28</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>beena part to do. the airline industry has not...</td>\n",
       "      <td>[beena, part, airline, industry, part, move, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-18 19:21:01</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>it's beaten it by about 0.1, 0.12 degrees cels...</td>\n",
       "      <td>[beaten, 01, 012, degrees, celsius, doesnt, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-05 21:48:46</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>contact more than expected, how. your co nta c...</td>\n",
       "      <td>[contact, expected, co, nta, ct, le, ns, expec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-05 21:13:33</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>where every time a marketplace is closed down,...</td>\n",
       "      <td>[every, time, marketplace, closed, another, ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-01-11 03:11:51</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>applause climate change, a controversial issue...</td>\n",
       "      <td>[applause, climate, change, controversial, iss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2020-01-07 10:27:25</td>\n",
       "      <td>MSNBC</td>\n",
       "      <td>they could be facing. the climate change has m...</td>\n",
       "      <td>[could, facing, climate, change, made, worse, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2020-01-10 01:57:54</td>\n",
       "      <td>MSNBC</td>\n",
       "      <td>fact that they've had a number of decisions th...</td>\n",
       "      <td>[fact, theyve, number, decisions, thrown, back...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2020-01-15 05:53:44</td>\n",
       "      <td>MSNBC</td>\n",
       "      <td>i think there were missed opportunities to tal...</td>\n",
       "      <td>[think, missed, opportunities, talk, things, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2020-01-05 03:55:58</td>\n",
       "      <td>MSNBC</td>\n",
       "      <td>potentially reshape the democratic primaries. ...</td>\n",
       "      <td>[potentially, reshape, democratic, primaries, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2020-01-14 05:43:03</td>\n",
       "      <td>MSNBC</td>\n",
       "      <td>beat donald trump, but that is the floor, not ...</td>\n",
       "      <td>[beat, donald, trump, floor, ceiling, call, co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94858 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          MatchDateTime  Station  \\\n",
       "1   2017-01-31 05:53:28  BBCNEWS   \n",
       "2   2017-01-18 19:21:01  BBCNEWS   \n",
       "3   2017-01-05 21:48:46  BBCNEWS   \n",
       "4   2017-01-05 21:13:33  BBCNEWS   \n",
       "5   2017-01-11 03:11:51  BBCNEWS   \n",
       "..                  ...      ...   \n",
       "198 2020-01-07 10:27:25    MSNBC   \n",
       "199 2020-01-10 01:57:54    MSNBC   \n",
       "200 2020-01-15 05:53:44    MSNBC   \n",
       "201 2020-01-05 03:55:58    MSNBC   \n",
       "202 2020-01-14 05:43:03    MSNBC   \n",
       "\n",
       "                                               Snippet  \\\n",
       "1    beena part to do. the airline industry has not...   \n",
       "2    it's beaten it by about 0.1, 0.12 degrees cels...   \n",
       "3    contact more than expected, how. your co nta c...   \n",
       "4    where every time a marketplace is closed down,...   \n",
       "5    applause climate change, a controversial issue...   \n",
       "..                                                 ...   \n",
       "198  they could be facing. the climate change has m...   \n",
       "199  fact that they've had a number of decisions th...   \n",
       "200  i think there were missed opportunities to tal...   \n",
       "201  potentially reshape the democratic primaries. ...   \n",
       "202  beat donald trump, but that is the floor, not ...   \n",
       "\n",
       "                                                Tokens  \n",
       "1    [beena, part, airline, industry, part, move, r...  \n",
       "2    [beaten, 01, 012, degrees, celsius, doesnt, se...  \n",
       "3    [contact, expected, co, nta, ct, le, ns, expec...  \n",
       "4    [every, time, marketplace, closed, another, ap...  \n",
       "5    [applause, climate, change, controversial, iss...  \n",
       "..                                                 ...  \n",
       "198  [could, facing, climate, change, made, worse, ...  \n",
       "199  [fact, theyve, number, decisions, thrown, back...  \n",
       "200  [think, missed, opportunities, talk, things, l...  \n",
       "201  [potentially, reshape, democratic, primaries, ...  \n",
       "202  [beat, donald, trump, floor, ceiling, call, co...  \n",
       "\n",
       "[94858 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data preprocessing\n",
    "df['Tokens'] = df['Snippet'].str.lower()\n",
    "df['Tokens'] = df['Tokens'].apply(remove_punctuation)\n",
    "df['Tokens'] = tokenize(df['Tokens'].str)\n",
    "df['Tokens'] = df['Tokens'].apply(remove_stopwords)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store as csv\n",
    "df.to_csv('data/news_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2106506 tokens in the data.\n",
      "There are 46276 unique tokens in the data.\n",
      "There are 12859252 characters in the data.\n",
      "The lexical diversity is 0.022 in the data.\n",
      "Top 5 most common tokens:\n",
      "climate: 85155 occurrences\n",
      "change: 77697 occurrences\n",
      "global: 24371 occurrences\n",
      "warming: 21077 occurrences\n",
      "president: 13685 occurrences\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2106506, 46276, 0.02196813111379697, 12859252]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_tokens=[token for sublist in df['Tokens'] for token in sublist]\n",
    "descriptive_stats(combined_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADS500B",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
