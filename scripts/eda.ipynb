{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from eda import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchdatetime</th>\n",
       "      <th>station</th>\n",
       "      <th>snippet</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-31 05:53:28</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>beena part to do. the airline industry has not...</td>\n",
       "      <td>['beena', 'part', 'airline', 'industry', 'part...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-18 19:21:01</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>it's beaten it by about 0.1, 0.12 degrees cels...</td>\n",
       "      <td>['beaten', '01', '012', 'degrees', 'celsius', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05 21:48:46</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>contact more than expected, how. your co nta c...</td>\n",
       "      <td>['contact', 'expected', 'co', 'nta', 'ct', 'le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-05 21:13:33</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>where every time a marketplace is closed down,...</td>\n",
       "      <td>['every', 'time', 'marketplace', 'closed', 'an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-11 03:11:51</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>applause climate change, a controversial issue...</td>\n",
       "      <td>['applause', 'climate', 'change', 'controversi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         matchdatetime  station  \\\n",
       "0  2017-01-31 05:53:28  BBCNEWS   \n",
       "1  2017-01-18 19:21:01  BBCNEWS   \n",
       "2  2017-01-05 21:48:46  BBCNEWS   \n",
       "3  2017-01-05 21:13:33  BBCNEWS   \n",
       "4  2017-01-11 03:11:51  BBCNEWS   \n",
       "\n",
       "                                             snippet  \\\n",
       "0  beena part to do. the airline industry has not...   \n",
       "1  it's beaten it by about 0.1, 0.12 degrees cels...   \n",
       "2  contact more than expected, how. your co nta c...   \n",
       "3  where every time a marketplace is closed down,...   \n",
       "4  applause climate change, a controversial issue...   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['beena', 'part', 'airline', 'industry', 'part...  \n",
       "1  ['beaten', '01', '012', 'degrees', 'celsius', ...  \n",
       "2  ['contact', 'expected', 'co', 'nta', 'ct', 'le...  \n",
       "3  ['every', 'time', 'marketplace', 'closed', 'an...  \n",
       "4  ['applause', 'climate', 'change', 'controversi...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/news_cleaned.csv')\n",
    "df.columns = df.columns.str.lower()\n",
    "df = df.drop(columns=['unnamed: 0', 'snippet_no_climate'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchdatetime</th>\n",
       "      <th>station</th>\n",
       "      <th>snippet</th>\n",
       "      <th>tokens</th>\n",
       "      <th>snippet_no_climate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-31 05:53:28</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>beena part to do. the airline industry has not...</td>\n",
       "      <td>['beena', 'part', 'airline', 'industry', 'part...</td>\n",
       "      <td>beena part to do. the airline industry has not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-18 19:21:01</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>it's beaten it by about 0.1, 0.12 degrees cels...</td>\n",
       "      <td>['beaten', '01', '012', 'degrees', 'celsius', ...</td>\n",
       "      <td>it's beaten it by about 0.1, 0.12 degrees cels...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05 21:48:46</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>contact more than expected, how. your co nta c...</td>\n",
       "      <td>['contact', 'expected', 'co', 'nta', 'ct', 'le...</td>\n",
       "      <td>contact more than expected, how. your co nta c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-05 21:13:33</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>where every time a marketplace is closed down,...</td>\n",
       "      <td>['every', 'time', 'marketplace', 'closed', 'an...</td>\n",
       "      <td>where every time a marketplace is closed down,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-11 03:11:51</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>applause climate change, a controversial issue...</td>\n",
       "      <td>['applause', 'climate', 'change', 'controversi...</td>\n",
       "      <td>applause , a controversial issue which has see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-01-18 13:51:21</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>with mr trump's thinking. he's a former attorn...</td>\n",
       "      <td>['mr', 'trumps', 'thinking', 'hes', 'former', ...</td>\n",
       "      <td>with mr trump's thinking. he's a former attorn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-01-30 23:38:49</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>the problems we are facing today in europe? cl...</td>\n",
       "      <td>['problems', 'facing', 'today', 'europe', 'cli...</td>\n",
       "      <td>the problems we are facing today in europe? ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-01-18 21:43:18</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>agreement, a global deal that came into force ...</td>\n",
       "      <td>['agreement', 'global', 'deal', 'came', 'force...</td>\n",
       "      <td>agreement, a global deal that came into force ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-01-10 02:10:55</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>patrol on the far side. meanwhile, in italy, t...</td>\n",
       "      <td>['patrol', 'far', 'side', 'meanwhile', 'italy'...</td>\n",
       "      <td>patrol on the far side. meanwhile, in italy, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-01-18 23:09:59</td>\n",
       "      <td>BBCNEWS</td>\n",
       "      <td>set by the paris climate agreement, a global d...</td>\n",
       "      <td>['set', 'paris', 'climate', 'agreement', 'glob...</td>\n",
       "      <td>set by the paris climate agreement, a global d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         matchdatetime  station  \\\n",
       "0  2017-01-31 05:53:28  BBCNEWS   \n",
       "1  2017-01-18 19:21:01  BBCNEWS   \n",
       "2  2017-01-05 21:48:46  BBCNEWS   \n",
       "3  2017-01-05 21:13:33  BBCNEWS   \n",
       "4  2017-01-11 03:11:51  BBCNEWS   \n",
       "5  2017-01-18 13:51:21  BBCNEWS   \n",
       "6  2017-01-30 23:38:49  BBCNEWS   \n",
       "7  2017-01-18 21:43:18  BBCNEWS   \n",
       "8  2017-01-10 02:10:55  BBCNEWS   \n",
       "9  2017-01-18 23:09:59  BBCNEWS   \n",
       "\n",
       "                                             snippet  \\\n",
       "0  beena part to do. the airline industry has not...   \n",
       "1  it's beaten it by about 0.1, 0.12 degrees cels...   \n",
       "2  contact more than expected, how. your co nta c...   \n",
       "3  where every time a marketplace is closed down,...   \n",
       "4  applause climate change, a controversial issue...   \n",
       "5  with mr trump's thinking. he's a former attorn...   \n",
       "6  the problems we are facing today in europe? cl...   \n",
       "7  agreement, a global deal that came into force ...   \n",
       "8  patrol on the far side. meanwhile, in italy, t...   \n",
       "9  set by the paris climate agreement, a global d...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['beena', 'part', 'airline', 'industry', 'part...   \n",
       "1  ['beaten', '01', '012', 'degrees', 'celsius', ...   \n",
       "2  ['contact', 'expected', 'co', 'nta', 'ct', 'le...   \n",
       "3  ['every', 'time', 'marketplace', 'closed', 'an...   \n",
       "4  ['applause', 'climate', 'change', 'controversi...   \n",
       "5  ['mr', 'trumps', 'thinking', 'hes', 'former', ...   \n",
       "6  ['problems', 'facing', 'today', 'europe', 'cli...   \n",
       "7  ['agreement', 'global', 'deal', 'came', 'force...   \n",
       "8  ['patrol', 'far', 'side', 'meanwhile', 'italy'...   \n",
       "9  ['set', 'paris', 'climate', 'agreement', 'glob...   \n",
       "\n",
       "                                  snippet_no_climate  \n",
       "0  beena part to do. the airline industry has not...  \n",
       "1  it's beaten it by about 0.1, 0.12 degrees cels...  \n",
       "2  contact more than expected, how. your co nta c...  \n",
       "3  where every time a marketplace is closed down,...  \n",
       "4  applause , a controversial issue which has see...  \n",
       "5  with mr trump's thinking. he's a former attorn...  \n",
       "6      the problems we are facing today in europe? ?  \n",
       "7  agreement, a global deal that came into force ...  \n",
       "8  patrol on the far side. meanwhile, in italy, t...  \n",
       "9  set by the paris climate agreement, a global d...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_bigram_phrases(text, phrases_to_remove):\n",
    "    for phrase in phrases_to_remove:\n",
    "        text = text.replace(phrase, '')\n",
    "    return text\n",
    "\n",
    "# Climate bi-gram phrases\n",
    "climate_grams = [\"climate change\", \"global warming\", \"climate crisis\", \"greenhouse gas\", \"greenhouse gases\", \"carbon tax\"]\n",
    "\n",
    "# Apply the custom function to each row\n",
    "df['snippet_no_climate'] = df['snippet'].map(lambda x: remove_bigram_phrases(x, climate_grams))\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-Of-Words Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_ngram(corpus: pd.Series, n_phrases: int=20, ngram_min: int=2, ngram_max: int=2, \n",
    "                    remove_stopwords: bool=True, remove_climate_phrases: bool=True) -> sns.barplot:\n",
    "    \"\"\"\n",
    "    Finds most common n-gram phrases in a given corpus and plot its distribution.\n",
    "    :param corpus: pd.Series, text column\n",
    "    :param n_phrases: int, number of n-gram phrases to return\n",
    "    :param ngram_min: int, lower n-gram range boundary\n",
    "    :param ngram_max: int, upper n-gram range boundary\n",
    "    :param stopwords: bool, toggle stop word removal\n",
    "    :return: pd.DataFrame of n-grams and their respective counts\n",
    "    \"\"\"\n",
    "    # Check if n-grams should include stop words\n",
    "    if remove_stopwords:\n",
    "        stopwords = 'english'\n",
    "    else:\n",
    "        stopwords = None\n",
    "\n",
    "    try: \n",
    "        vec = CountVectorizer(ngram_range=(ngram_min, ngram_max), stop_words=stopwords).fit(corpus)\n",
    "\n",
    "        bag_of_words = vec.transform(corpus)\n",
    "        sum_words = bag_of_words.sum(axis=0)\n",
    "        \n",
    "        words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "        words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Store word frequencies as pd.DataFrame for plotting\n",
    "        df = pd.DataFrame(words_freq[:n_phrases], columns=['phrases', 'count'])\n",
    "\n",
    "        plot_ngram_dist(df, ngram_max, remove_stopwords, remove_climate_phrases)\n",
    "\n",
    "    except ValueError:\n",
    "        print(\"Invalid input\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_ngram_dist(df: pd.DataFrame, ngram_max: int, remove_stopwords: bool, remove_climate_phrases: bool) -> None:\n",
    "    \"\"\" \n",
    "    Plot the n-gram distribution.\n",
    "    :param df: pd.DataFrame, dataframe of climate news snippets.\n",
    "    :return: sns.histplot\n",
    "    \"\"\"\n",
    "    sns.set_style('darkgrid')\n",
    "    sns.set_theme(rc={'figure.figsize':(10,4)})\n",
    "\n",
    "    # Plot bar chart of n-gram frequencies\n",
    "    sns.barplot(df, x='snippets', y='count', legend=False)\n",
    "    \n",
    "    # Title conditions\n",
    "    if ngram_max == 2:\n",
    "        ngram = 'Bi'\n",
    "    elif ngram_max == 3:\n",
    "        ngram = 'Tri'\n",
    "    elif ngram_max == 4:\n",
    "        ngram = 'Four'\n",
    "    else:\n",
    "        ngram = 'N'\n",
    "\n",
    "    if remove_stopwords:\n",
    "        sw_condition = 'After'  \n",
    "    else:  \n",
    "        sw_condition = 'Before'\n",
    "\n",
    "    if remove_climate_phrases:\n",
    "        cp_condition = 'And Climate Phrases' \n",
    "    else: \n",
    "        cp_condition = ''\n",
    "    \n",
    "    plt.title(f\"{ngram}-Gram Distribution {sw_condition} Removing Stop Words {cp_condition}\", fontweight='bold')\n",
    "    plt.xticks(rotation=60, fontsize=8)\n",
    "    plt.xlabel(\"N-Grams\")\n",
    "    plt.ylabel(\"Count\")\n",
    "\n",
    "    # Save and show plot\n",
    "    plt.savefig(f'figures/{ngram_max}_gram_dist_{sw_condition}_sw_{cp_condition}_removal.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid input\n"
     ]
    }
   ],
   "source": [
    "# Bi-gram distribution Before Removing Stopwords (Keep CLimate Phrases)\n",
    "bi_sw_df = get_top_n_ngram(corpus=df['snippet'], remove_stopwords=False, remove_climate_phrases=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrases</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>climate change</td>\n",
       "      <td>75024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of the</td>\n",
       "      <td>20464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>global warming</td>\n",
       "      <td>19862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in the</td>\n",
       "      <td>16455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on the</td>\n",
       "      <td>9756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          phrases  count\n",
       "0  climate change  75024\n",
       "1          of the  20464\n",
       "2  global warming  19862\n",
       "3          in the  16455\n",
       "4          on the   9756"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_sw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid input\n"
     ]
    }
   ],
   "source": [
    "# Bi-gram distribution After Removing Stopwords (Keep CLimate Phrases)\n",
    "bi_nosw_df = get_top_n_ngram(corpus=df['snippet'], remove_climate_phrases=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrases</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>climate change</td>\n",
       "      <td>75040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>global warming</td>\n",
       "      <td>19862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>greenhouse gas</td>\n",
       "      <td>3297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>president obama</td>\n",
       "      <td>2595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>united states</td>\n",
       "      <td>2573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           phrases  count\n",
       "0   climate change  75040\n",
       "1   global warming  19862\n",
       "2   greenhouse gas   3297\n",
       "3  president obama   2595\n",
       "4    united states   2573"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_nosw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid input\n"
     ]
    }
   ],
   "source": [
    "# Bi-gram distribution After Removing CLimate Phrases (Stop Words Removed)\n",
    "bi_nocp_df = get_top_n_ngram(corpus=df['snippet_no_climate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrases</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>president obama</td>\n",
       "      <td>2595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>united states</td>\n",
       "      <td>2573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>president trump</td>\n",
       "      <td>2305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>donald trump</td>\n",
       "      <td>2206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>white house</td>\n",
       "      <td>1872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           phrases  count\n",
       "0  president obama   2595\n",
       "1    united states   2573\n",
       "2  president trump   2305\n",
       "3     donald trump   2206\n",
       "4      white house   1872"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_nocp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid input\n"
     ]
    }
   ],
   "source": [
    "# Four-gram distribution Before Removing CLimate Phrases (Stop Words Removed)\n",
    "fourgram_sw_df = get_top_n_ngram(corpus=df['snippet'], ngram_min=4, ngram_max=4, \n",
    "                                 remove_stopwords=False, remove_climate_phrases=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrases</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>that climate change is</td>\n",
       "      <td>1679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>climate change is real</td>\n",
       "      <td>1119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we re going to</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>on climate change and</td>\n",
       "      <td>1067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of climate change and</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  phrases  count\n",
       "0  that climate change is   1679\n",
       "1  climate change is real   1119\n",
       "2          we re going to   1093\n",
       "3   on climate change and   1067\n",
       "4   of climate change and    939"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourgram_sw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid input\n"
     ]
    }
   ],
   "source": [
    "# Four-gram distribution Before Removing CLimate Phrases (Stop Words Removed)\n",
    "fourgram_nosw_df = get_top_n_ngram(corpus=df['snippet'], ngram_min=4, ngram_max=4,\n",
    "                remove_climate_phrases=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrases</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>going touched climate change</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cut greenhouse gas emissions</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>melting pot impacted species</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pot impacted species going</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>impacted species going touched</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          phrases  count\n",
       "0    going touched climate change    620\n",
       "1    cut greenhouse gas emissions    454\n",
       "2    melting pot impacted species    415\n",
       "3      pot impacted species going    415\n",
       "4  impacted species going touched    415"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourgram_nosw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid input\n"
     ]
    }
   ],
   "source": [
    "# Four-gram distribution After Removing CLimate Phrases (Stop Words Removed)\n",
    "fourgram_nocp_df = get_top_n_ngram(corpus=df['snippet_no_climate'], ngram_min=4, ngram_max=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrases</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>melting pot impacted species</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pot impacted species going</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>impacted species going touched</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>potential just keeps growing</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cars talk road sensors</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          phrases  count\n",
       "0    melting pot impacted species    415\n",
       "1      pot impacted species going    415\n",
       "2  impacted species going touched    415\n",
       "3    potential just keeps growing    313\n",
       "4          cars talk road sensors    242"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourgram_nocp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi_sw_df = bi_sw_df.rename(columns={'snippets': 'Bi-Gram w/ Stopwords', 'count': 'Bi-Gram w/ Stopwords Count'})\n",
    "# bi_nosw_df = bi_nosw_df.rename(columns={'snippets': 'Bi-Gram w/o Stopwords', 'count': 'Bi-Gram w/o Stopwords Count'})\n",
    "\n",
    "# bi_gram_df = pd.concat([bi_sw_df, \n",
    "#                        bi_nosw_df],\n",
    "#                        ignore_index=False)\n",
    "# bi_gram_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climate-lang-processing-BkjdiFik",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
