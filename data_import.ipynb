{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = glob.glob(\"TelevisionNews/*.csv\")\n",
    "df = []\n",
    "for file in csv_files:\n",
    "    csv = pd.read_csv(file, header=None, names=['URL', 'MatchDateTime', 'Station', 'Show', 'IAShowID','IAPreviewThumb','Snippet'])\n",
    "    csv = csv.iloc[1:] #drow first row containing column names \n",
    "    df.append(csv)\n",
    "df = pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchDateTime</th>\n",
       "      <th>Station</th>\n",
       "      <th>Snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3/15/2011 15:11:06</td>\n",
       "      <td>FOXNEWS</td>\n",
       "      <td>forward. greg: i suppose worth pointing out th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3/31/2011 13:16:41</td>\n",
       "      <td>FOXNEWS</td>\n",
       "      <td>threaten a government shutdown. that's what's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3/30/2011 17:29:04</td>\n",
       "      <td>FOXNEWS</td>\n",
       "      <td>and less likely. in any case, president obama ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/14/2011 22:09:55</td>\n",
       "      <td>FOXNEWS</td>\n",
       "      <td>environmental catastrophe in another part of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3/15/2011 8:09:55</td>\n",
       "      <td>FOXNEWS</td>\n",
       "      <td>environmental catastrophe in another part of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2/24/2012 14:24:07</td>\n",
       "      <td>CNN</td>\n",
       "      <td>will galvanize them to do stuff and understand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2/23/2012 9:20:57</td>\n",
       "      <td>CNN</td>\n",
       "      <td>ballot. still to come on wbt, china, the u.s.,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2/10/2012 15:57:13</td>\n",
       "      <td>CNN</td>\n",
       "      <td>or newt gingrich all that much at all. he was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2/29/2012 13:56:13</td>\n",
       "      <td>CNN</td>\n",
       "      <td>endless primary with hillary clinton. there we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2/24/2012 14:23:51</td>\n",
       "      <td>CNN</td>\n",
       "      <td>australian officials, is this will be a really...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94858 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MatchDateTime  Station  \\\n",
       "1   3/15/2011 15:11:06  FOXNEWS   \n",
       "2   3/31/2011 13:16:41  FOXNEWS   \n",
       "3   3/30/2011 17:29:04  FOXNEWS   \n",
       "4   3/14/2011 22:09:55  FOXNEWS   \n",
       "5    3/15/2011 8:09:55  FOXNEWS   \n",
       "..                 ...      ...   \n",
       "32  2/24/2012 14:24:07      CNN   \n",
       "33   2/23/2012 9:20:57      CNN   \n",
       "34  2/10/2012 15:57:13      CNN   \n",
       "35  2/29/2012 13:56:13      CNN   \n",
       "36  2/24/2012 14:23:51      CNN   \n",
       "\n",
       "                                              Snippet  \n",
       "1   forward. greg: i suppose worth pointing out th...  \n",
       "2   threaten a government shutdown. that's what's ...  \n",
       "3   and less likely. in any case, president obama ...  \n",
       "4   environmental catastrophe in another part of t...  \n",
       "5   environmental catastrophe in another part of t...  \n",
       "..                                                ...  \n",
       "32  will galvanize them to do stuff and understand...  \n",
       "33  ballot. still to come on wbt, china, the u.s.,...  \n",
       "34  or newt gingrich all that much at all. he was ...  \n",
       "35  endless primary with hillary clinton. there we...  \n",
       "36  australian officials, is this will be a really...  \n",
       "\n",
       "[94858 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= df.drop(['URL','Show','IAShowID', 'IAPreviewThumb'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MatchDateTime    datetime64[ns]\n",
       "Station          string[python]\n",
       "Snippet          string[python]\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change dtypes \n",
    "df['MatchDateTime'] = pd.to_datetime(df['MatchDateTime'])\n",
    "df['Station'] = df['Station'].astype('string')\n",
    "df['Snippet'] = df['Snippet'].astype('string')\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions\n",
    "\n",
    "punctuation = set(punctuation) # speeds up comparison\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(tokens) :\n",
    "    return [token for token in tokens if token not in sw]\n",
    "    return(tokens)\n",
    "\n",
    "def remove_punctuation(text) :\n",
    "    return \"\".join(ch for ch in text if ch not in punctuation)\n",
    "\n",
    "def tokenize(text) :\n",
    "    tokens = text.split()\n",
    "    return(tokens)\n",
    "\n",
    "def descriptive_stats(tokens, verbose=True) :\n",
    "    num_tokens=len(tokens)\n",
    "    num_unique_tokens = len(set(tokens))\n",
    "    lexical_diversity = num_unique_tokens/num_tokens\n",
    "    num_characters = sum(len(token) for token in tokens)\n",
    "\n",
    "    if verbose :\n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "\n",
    "        # print the five most common tokens\n",
    "        counter = Counter(tokens)\n",
    "        top_5_tokens = counter.most_common(5)\n",
    "        print(\"Top 5 most common tokens:\")\n",
    "        for token, count in top_5_tokens:\n",
    "            print(f\"{token}: {count} occurrences\")\n",
    "\n",
    "    return([num_tokens, num_unique_tokens,\n",
    "            lexical_diversity,\n",
    "            num_characters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of news snippets: 94858\n",
      "News stations: <StringArray>\n",
      "['FOXNEWS', 'MSNBC', 'BBCNEWS', 'CNN']\n",
      "Length: 4, dtype: string\n",
      "\n",
      "Count of snippets for each news station: \n",
      " Station\n",
      "MSNBC      26429\n",
      "FOXNEWS    25865\n",
      "BBCNEWS    23260\n",
      "CNN        19304\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of news snippets:\", len(df))\n",
    "print(\"News stations:\", df['Station'].unique())\n",
    "print(\"\\nCount of snippets for each news station: \\n\",df['Station'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MatchDateTime</th>\n",
       "      <th>Station</th>\n",
       "      <th>Snippet</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-03-15 15:11:06</td>\n",
       "      <td>FOXNEWS</td>\n",
       "      <td>forward. greg: i suppose worth pointing out th...</td>\n",
       "      <td>[forward, greg, suppose, worth, pointing, gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-03-31 13:16:41</td>\n",
       "      <td>FOXNEWS</td>\n",
       "      <td>threaten a government shutdown. that's what's ...</td>\n",
       "      <td>[threaten, government, shutdown, thats, whats,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-03-30 17:29:04</td>\n",
       "      <td>FOXNEWS</td>\n",
       "      <td>and less likely. in any case, president obama ...</td>\n",
       "      <td>[less, likely, case, president, obama, would, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-03-14 22:09:55</td>\n",
       "      <td>FOXNEWS</td>\n",
       "      <td>environmental catastrophe in another part of t...</td>\n",
       "      <td>[environmental, catastrophe, another, part, wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011-03-15 08:09:55</td>\n",
       "      <td>FOXNEWS</td>\n",
       "      <td>environmental catastrophe in another part of t...</td>\n",
       "      <td>[environmental, catastrophe, another, part, wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2012-02-24 14:24:07</td>\n",
       "      <td>CNN</td>\n",
       "      <td>will galvanize them to do stuff and understand...</td>\n",
       "      <td>[galvanize, stuff, understand, climate, change...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2012-02-23 09:20:57</td>\n",
       "      <td>CNN</td>\n",
       "      <td>ballot. still to come on wbt, china, the u.s.,...</td>\n",
       "      <td>[ballot, still, come, wbt, china, us, russia, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2012-02-10 15:57:13</td>\n",
       "      <td>CNN</td>\n",
       "      <td>or newt gingrich all that much at all. he was ...</td>\n",
       "      <td>[newt, gingrich, much, really, trying, say, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2012-02-29 13:56:13</td>\n",
       "      <td>CNN</td>\n",
       "      <td>endless primary with hillary clinton. there we...</td>\n",
       "      <td>[endless, primary, hillary, clinton, policy, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2012-02-24 14:23:51</td>\n",
       "      <td>CNN</td>\n",
       "      <td>australian officials, is this will be a really...</td>\n",
       "      <td>[australian, officials, really, good, thing, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94858 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MatchDateTime  Station  \\\n",
       "1  2011-03-15 15:11:06  FOXNEWS   \n",
       "2  2011-03-31 13:16:41  FOXNEWS   \n",
       "3  2011-03-30 17:29:04  FOXNEWS   \n",
       "4  2011-03-14 22:09:55  FOXNEWS   \n",
       "5  2011-03-15 08:09:55  FOXNEWS   \n",
       "..                 ...      ...   \n",
       "32 2012-02-24 14:24:07      CNN   \n",
       "33 2012-02-23 09:20:57      CNN   \n",
       "34 2012-02-10 15:57:13      CNN   \n",
       "35 2012-02-29 13:56:13      CNN   \n",
       "36 2012-02-24 14:23:51      CNN   \n",
       "\n",
       "                                              Snippet  \\\n",
       "1   forward. greg: i suppose worth pointing out th...   \n",
       "2   threaten a government shutdown. that's what's ...   \n",
       "3   and less likely. in any case, president obama ...   \n",
       "4   environmental catastrophe in another part of t...   \n",
       "5   environmental catastrophe in another part of t...   \n",
       "..                                                ...   \n",
       "32  will galvanize them to do stuff and understand...   \n",
       "33  ballot. still to come on wbt, china, the u.s.,...   \n",
       "34  or newt gingrich all that much at all. he was ...   \n",
       "35  endless primary with hillary clinton. there we...   \n",
       "36  australian officials, is this will be a really...   \n",
       "\n",
       "                                               Tokens  \n",
       "1   [forward, greg, suppose, worth, pointing, gene...  \n",
       "2   [threaten, government, shutdown, thats, whats,...  \n",
       "3   [less, likely, case, president, obama, would, ...  \n",
       "4   [environmental, catastrophe, another, part, wo...  \n",
       "5   [environmental, catastrophe, another, part, wo...  \n",
       "..                                                ...  \n",
       "32  [galvanize, stuff, understand, climate, change...  \n",
       "33  [ballot, still, come, wbt, china, us, russia, ...  \n",
       "34  [newt, gingrich, much, really, trying, say, fo...  \n",
       "35  [endless, primary, hillary, clinton, policy, i...  \n",
       "36  [australian, officials, really, good, thing, a...  \n",
       "\n",
       "[94858 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data preprocessing\n",
    "df['Tokens'] = df['Snippet'].str.lower()\n",
    "df['Tokens'] = df['Tokens'].apply(remove_punctuation)\n",
    "df['Tokens'] = tokenize(df['Tokens'].str)\n",
    "df['Tokens'] = df['Tokens'].apply(remove_stopwords)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2106506 tokens in the data.\n",
      "There are 46276 unique tokens in the data.\n",
      "There are 12859252 characters in the data.\n",
      "The lexical diversity is 0.022 in the data.\n",
      "Top 5 most common tokens:\n",
      "climate: 85155 occurrences\n",
      "change: 77697 occurrences\n",
      "global: 24371 occurrences\n",
      "warming: 21077 occurrences\n",
      "president: 13685 occurrences\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2106506, 46276, 0.02196813111379697, 12859252]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_tokens=[token for sublist in df['Tokens'] for token in sublist]\n",
    "descriptive_stats(combined_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADS500B",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
